{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing raw/any Dutch tweets \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This preprocessing was done before getting the tweets annotated for training. In other words, this preprocessing is for both the annotators and system input; however, the system architecture requires additional preprocessing which is presented in the other 2 notebooks containing the CNN-BiLSTM and the Baseline SVM **\n",
    "\n",
    "The preprocessing here involves the following: \n",
    "\n",
    "1.Getting only Dutch tweets. \n",
    "\n",
    "2.Getting only the tweets that are more than 25 characters. \n",
    "\n",
    "3.Removing the author of the tweet.\n",
    "\n",
    "4.Removing of hyperlinks and other unwanted characters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Import necessary modules**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from langdetect import detect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Split CSV file into desired columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'example_raw_tweets.csv' #or any other CSV containing raw tweets in this format\n",
    "def read_csv(filename, encoding='utf-8'):\n",
    "    \"\"\"\n",
    "    Reads a csv file using csv reader and splits each row into lists.\n",
    "    (Make sure the csv file contains all the correct columns and rows)\n",
    "    \"\"\"\n",
    "    authorlist = []\n",
    "    datelist = []\n",
    "    partylist = []\n",
    "    contentlist = []\n",
    "    with open(filename, 'r') as csvfile: \n",
    "        reader = csv.reader(csvfile, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            author = row[0]\n",
    "            date = row[1]\n",
    "            party = row[2]\n",
    "            content = row[3]\n",
    "            if author == 'AUTEUR': \n",
    "                continue\n",
    "            if date == 'DATUM':\n",
    "                continue\n",
    "            if party == 'PARTIJ': \n",
    "                continue\n",
    "            if content == 'CONTENT\"':\n",
    "                continue\n",
    "            contentlist.append(content)\n",
    "            authorlist.append(author)\n",
    "            partylist.append(party)\n",
    "            datelist.append(date)\n",
    "            \n",
    "\n",
    "    return authorlist, datelist, partylist, contentlist\n",
    "authorlist, datelist, partylist, contentlist = read_csv(filename) #date, party, content = read_csv(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Get only the tweets that are written in Dutch & are more than 25 characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2190"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_only_dutch(author, date, party, content):\n",
    "    \"\"\"\n",
    "    Using the langdetect package, it only gets the tweets written in dutch. \n",
    "    It also gets rid of tweets that have less than 25 characters. \n",
    "    \"\"\"\n",
    "    language = []\n",
    "    for tweet in content:\n",
    "        language.append(detect(tweet))\n",
    "    \n",
    "    zipped = list(zip(author, date, party, content, language))\n",
    "    nested_list = [list(item) for item in zipped]\n",
    "\n",
    "    only_dutch = []\n",
    "    for item in nested_list:\n",
    "        if 'nl' in item:\n",
    "            only_dutch.append(item)\n",
    "    \n",
    "    only_longer_tweets = []\n",
    "    for item in only_dutch: \n",
    "        if len(item[3]) > 25:   ## get only the tweets that are more than 25 characters. \n",
    "            only_longer_tweets.append(item)\n",
    "            \n",
    "    author = []\n",
    "    date = []\n",
    "    party = []\n",
    "    content = []\n",
    "    for item in only_longer_tweets:\n",
    "        author.append(item[0])\n",
    "        date.append(item[1])\n",
    "        party.append(item[2])\n",
    "        content.append(item[3])\n",
    "        \n",
    "    return author, date, party, content\n",
    "\n",
    "author, date, party, content = get_only_dutch(authorlist, datelist, partylist, contentlist)\n",
    "len(content)  \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. More preprocessing using regular expressions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(content):\n",
    "    \"\"\"\n",
    "    Using output of 'read_csv' or 'read_csv_2nd_way' function, cleans author list \n",
    "    to leave behind pure content only.\n",
    "    Module to use: regex, 'import re'\n",
    "    \"\"\"\n",
    "    cont=[]\n",
    "    for item in content: \n",
    "        first = re.sub(r'^.*?:', '', item)\n",
    "        cont.append(first)\n",
    "    cleaned1=[]\n",
    "    for item in cont:\n",
    "        links = re.sub(r\"http\\S+\",'', item)\n",
    "        cleaned1.append(links) \n",
    "    cleaned2=[]\n",
    "    for item in cleaned1:\n",
    "        users = re.sub(\"@[^:]*:\", '', item) #removes the users that posted/retweeted, but not the users mentioned \n",
    "                                            #inside the tweet\n",
    "        cleaned2.append(users)\n",
    "        #users = re.sub(r'@\\S+','', item)  #this line removes all users, but we want to keep the ones in the tweet.\n",
    "    check_nr_tweets = len(cleaned2)\n",
    "   \n",
    "    cleaned3 = []\n",
    "    for item in cleaned2:\n",
    "        unicodes=re.sub(r'(\\\\u[0-9A-Fa-f]+)','', item)\n",
    "        #unicodes=item.replace('\\u2066','').replace('\\u2069','').replace('\\xa0', '')\n",
    "        cleaned3.append(unicodes)\n",
    "    \n",
    "    #cleaned4 = []\n",
    "    #for item in cleaned3: \n",
    "        #unicodes2=item.decode('unicode_escape')\n",
    "        #cleaned4.append(unicodes2)\n",
    "    \n",
    "    return cleaned3\n",
    "\n",
    "cleaned = clean_tweets(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' RT  â€˜Laat de superrijken gewoon hun belastingen betalen . #tegenlicht ', ' RT  De politiek in het bijzonder #D66 #GL @COCNederland kijken weg hebben het druk met Polen en Hongarije te bekritiseren. #homogeweld ', ' RT  De euro strompelt van crisis naar crisis. De huidige situatie is onhoudbaar en benadeelt zowel Noord-Europa als Zuid-Europa. Het is tijd om de euro te ontvlechten. #FVD  via @fvdemocratie', ' Op uitnodiging van  Over superrijken die geen belasting betalen, dus niet bijdragen maar wel profiteren van de samenleving en vervolgens mooi sier maken met kruimeltjes liefdadigheid. Waarom pikken wij dit nog? ', ' RT  Een succesvolle maatschappij is een vooruitgangsmachine, maar die machine is kapot - schrijver Anand Giridharadas #tegenlicht ']\n"
     ]
    }
   ],
   "source": [
    "print(cleaned[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
